## **Compiler I: Syntax Analysis**

## 编译器第一部分 句法分析

The previous chapter introduced *Jack*—a simple object-based programming language whose syntax resembles that of Java and C#. In this chapter we start building a compiler for the Jack language. A compiler is a program that translates programs from a source language into a target language. The translation process, known as compilation, is conceptually based on two distinct tasks. First, we have to understand the syntax of the source program, and, from it, uncover the program’s semantics. For example, the parsing of the code can reveal that the program seeks to declare an array or manipulate an object. This information enables us to reconstruct the program’s logic using the syntax of the target language. The first task, typically called syntax analysis, is described in this chapter; the second task—code generation—is taken up in chapter 11.

**上一章介绍了Jack —一种简单的基于对象的编程语言，其语法类似于Java和C＃。 在本章中，我们开始为Jack语言构建编译器。 编译器是将程序从源语言转换为目标语言的程序。 翻译过程称为编译，从概念上讲是基于两个不同的任务。 首先，我们必须了解源程序的语法，并从中了解源程序的语义。 例如，代码的解析可以揭示程序试图声明一个数组或操作一个对象。 这些信息使我们能够使用目标语言的语法来重构程序的逻辑。 本章介绍了第一个任务，通常称为语法分析。 第二个任务-代码生成-在第11章中讨论。**

How can we tell that a compiler is capable of “understanding” the language’s syntax? Well, as long as the code generated by the compiler is doing what it is supposed to do, we can optimistically assume that the compiler is operating properly. Yet in this chapter we build **only the syntax analyzer module** of the compiler, with no code generation capabilities. If we wish to unit-test the syntax analyzer in isolation, we have to contrive some passive way to demonstrate that it “understands” the source program. **Our solution is to have the syntax analyzer output an XML file whose format reflects the syntactic structure of the input program.** By inspecting the generated XML output, we should be able to ascertain that the analyzer is parsing input programs correctly.

**我们如何才能知道编译器能够“理解”该语言的语法？ 好吧，只要编译器生成的代码能够执行预期的工作，我们就可以乐观地假设编译器运行正常。 但是在本章中，我们仅构建编译器的语法分析器模块，而没有代码生成功能。 如果我们希望对语法分析器进行单独的单元测试，则必须设计某种被动方式来证明它“理解”了源程序。 我们的解决方案是让语法分析器输出一个XML文件，该文件的格式反映了输入程序的语法结构。 通过检查生成的XML输出，我们应该能够确定分析器正在正确解析输入程序。**



总结：关于编译器的语法分析部分，为了证明正确，可以依靠输出含有程序语法结构的XML文件来证明。



The chapter starts with a Background section that surveys the minimal set of concepts necessary for building a syntax analyzer: lexical analysis, context-free grammars, parse trees, and recursive descent algorithms for building them. This sets the stage for a Specification section that presents the formal grammar of the Jack language and the format of the output that a Jack analyzer is expected to generate. The Implementation section proposes a software architecture for constructing a Jack analyzer, along with a suggested API. As usual, the final Project section gives step-by-step instructions and test programs for actually building and testing the syntax analyzer. In the next chapter, this analyzer will be extended into a full-scale compiler.

**本章从“背景”部分开始，该部分概述了构建语法分析器所需的最少概念集：词法分析，无上下文语法，语法分析树和用于构建它们的递归算法。 这为“规范”部分奠定了基础，该部分介绍了杰克语言的形式语法以及杰克分析器预期生成的输出格式。 “实现”部分提出了用于构建Jack分析器的软件体系结构以及建议的API。 与往常一样，最后的“项目”部分提供了有关实际构建和测试语法分析器的逐步说明和测试程序。 在下一章中，此分析器将扩展为完整的编译器。**



Writing a compiler from scratch is a task that brings to bear several fundamental topics in computer science. It requires an understanding of language translation and parsing techniques, use of classical data structures like trees and hash tables, and application of sophisticated recursive compilation algorithms. For all these reasons, writing a compiler is also a challenging task. However, by splitting the compiler’s construction into two separate projects (or actually four, counting the VM projects as well), and by allowing the modular development and unit-testing of each part in isolation, we have turned the compiler’s development into a surprisingly manageable and self-contained activity.

**从头开始编写编译器是一项任务，需要承担计算机科学中的几个基本主题。 它需要了解语言翻译和解析技术，使用经典数据结构（例如树和哈希表）以及应用复杂的递归编译算法。 由于所有这些原因，编写编译器也是一项艰巨的任务。 但是，通过将编译器的构造划分为两个单独的项目（或实际上也包括四个，同时计算VM项目），并允许对每个部分进行模块化开发和单元测试，我们已经将编译器的开发变成了令人惊讶的可管理性 和独立的活动。**



Why should you go through the trouble of building a compiler? First, a hands-on grasp of compilation internals will turn you into a significantly better high-level programmer. Second, the same types of rules and grammars used for describing programming languages are also used for specifying the syntax of data sets in diverse applications ranging from computer graphics to database management to communications protocols to bioinformatics. Thus, while most programmers will not have to develop compilers in their careers, it is very likely that they will be required to parse and manipulate files of some complex syntax. These tasks will employ the same concepts and techniques used in the parsing of programming languages, as described in this chapter.

**为什么要折腾写编译器？ 首先，动手掌握编译内部知识将使您成为更好的高级程序员。 其次，用于描述编程语言的相同类型的规则和语法也用于指定从计算机图形到数据库管理到通信协议再到生物信息学的各种应用中的数据集语法。 因此，尽管大多数程序员在职业生涯中不必开发编译器，但很有可能需要他们解析和操作某些复杂语法的文件。 如本章所述，这些任务将采用与编程语言解析相同的概念和技术。**



# ***\*10.1 Background\****

A typical compiler consists of two main modules: syntax analysis and code generation. The syntax analysis task is usually divided further into two modules: tokenizing, or grouping of input characters into language atoms, and parsing, or attempting to match the resulting atoms stream to the syntax rules of the underlying language. Note that these activities are completely independent of the target language into which we seek to translate the source program. Since in this chapter we don’t deal with code generation, we have chosen to have the syntax analyzer output the parsed structure of the compiled program as an XML file. This decision has two benefits. First, the XML file can be easily viewed in any Web browser, demonstrating that the syntax analyzer is parsing source programs correctly. Second, the requirement to output this file explicitly forces us to write the syntax analyzer in a software architecture that can be later morphed into a full-scale compiler. In particular, in the next chapter we will simply replace the routines that generate the passive XML code with routines that generate executable VM code, leaving the rest of the compiler’s architecture intact (see figure 10.1).

**典型的编译器由两个主要模块组成：语法分析和代码生成。语法分析任务通常进一步分为两个模块：标记化或将输入字符分组为语言原子，以及解析或尝试将生成的原子流与基础语言的语法规则进行匹配。请注意，这些活动完全独立于我们试图将源程序翻译成的目标语言。由于在本章中我们不处理代码生成，因此我们选择了让语法分析器将已编译程序的解析结构作为XML文件输出。这个决定有两个好处。首先，可以在任何Web浏览器中轻松查看XML文件，这表明语法分析器正确地解析了源程序。其次，输出此文件的要求显式地迫使我们在一种软件体系结构中编写语法分析器，该体系结构随后可以转换为完整的编译器。特别是，在下一章中，我们将简单地将生成被动XML代码的例程替换为生成可执行VM代码的例程，而保留编译器其余结构的完整性（参见图10.1）。**



![](https://tva1.sinaimg.cn/large/0082zybpgy1gbtf1ec2quj30ds05dt8p.jpg)





In this chapter we focus only on the syntax analyzer module of the compiler, whose job is “understanding the structure of a program.” This notion needs some explanation. When humans read a computer program, they immediately recognize the program’s structure. They can identify where classes and methods begin and end, what are declarations, what are statements, what are expressions and how they are built, and so on. This understanding is not trivial, since it requires an ability to identify and classify nested patterns: In a typical program, classes contain methods that contain statements that contain other statements that contain expressions, and so on. In order to recognize these language constructs correctly, human cognition must recursively map them on the range of textual patterns permitted by the language syntax.

**在本章中，我们仅关注编译器的语法分析器模块，其工作是“了解程序的结构”。这一概念需要一些解释。 当人们阅读计算机程序时，他们会立即识别出程序的结构。 他们可以识别类和方法的开始和结束位置，什么是声明，什么是语句，什么是表达式以及如何构建它们，等等。 这种理解并非易事，因为它需要识别和分类嵌套模式的能力：在典型的程序中，类所包含的方法所包含的语句所包含的语句所包含的其他语句所包含的表达式等等。 为了正确识别这些语言结构，人类认知必须将它们递归地映射到语言语法所允许的文本模式范围内。**



When it comes to understanding a natural language like English, the question of how syntax rules are represented in the human brain and whether they are innate or acquired is a subject of intense debate. However, if we limit our attention to formal languages—artifacts whose simplicity hardly justifies the title “language”—we know precisely how to formalize their syntactic structure. In particular, programming languages are usually described using a set of rules called context-free grammar. To understand—parse—a given program means to determine the exact correspondence between the program’s text and the grammar’s rules. In order to do so, we first have to transform the program’s text into a list of tokens, as we now describe.

**在理解诸如英语之类的自然语言时，如何在人脑中表达语法规则以及这些语法规则是先天还是后天的问题引起了激烈的争论。 但是，如果我们将注意力集中在形式语言上，即其简单性难以证明“语言”这一称谓的文物，那么我们确切地知道如何将其句法结构形式化。 特别是，通常使用称为上下文无关文法的一组规则来描述编程语言。 要理解（解析）给定的程序，意味着要确定程序文本和语法规则之间的确切对应关系。 为此，我们首先必须将程序的文本转换为令牌列表，如我们现在所述。**



## **10.1.1 Lexical Analysis**

## 词法分析

In its plainest syntactic form, a program is simply a sequence of **characters**, stored in a text file. The first step in the syntax analysis of a program is to **group the characters into tokens** (as defined by the language syntax), while ignoring white space and comments. This step is usually called lexical analysis, scanning, or tokenizing. Once a program has been tokenized, **the tokens (rather than the characters) are viewed as its basic atoms**, and the **tokens stream becomes the main input of the compiler**. Figure 10.2 illustrates the tokenizing of a typical code fragment, taken from a C or Java program.

![](https://tva1.sinaimg.cn/large/0082zybpgy1gbtfn1pnm1j30dp061a9z.jpg)

#### 下图Lexical analysis.





![Lexical analysis.](https://tva1.sinaimg.cn/large/0082zybpgy1gbtfqai72gj30jm061jr9.jpg) 

**以最简单的句法形式，程序就是存储在文本文件中的一系列字符。 程序语法分析的第一步是将字符分组为标记（由语言语法定义），同时忽略空格和注释。 此步骤通常称为词法分析，扫描或标记化。 对程序进行标记后，将标记（而不是字符）视为其基本原子，并且标记流成为编译器的主要输入。 图10.2说明了从C或Java程序中提取的典型代码片段的标记化过程。**



As seen in figure 10.2, tokens fall into distinct categories, or types: while is a keyword, count is an identifier, <= is an operator, and so on. In general, each programming language specifies the types of tokens it allows, as well as the exact syntax rules for combining them into valid programmatic structures. For example, some languages may specify that “++” is a valid operator token, while other languages may not. In the latter case, an expression containing two consecutive “+” characters will be rendered invalid by the compiler.

**如图10.2所示，Token 分为不同的类别或类型：虽然是关键字，但count是标识符，<=是运算符，依此类推。 通常，每种编程语言都会指定其允许的Token类型，以及将其组合为有效程序结构的确切语法规则。 例如，某些语言可能指定“ ++”为有效的运算符，而其他语言则可能不是。 在后一种情况下，包含两个连续“ +”字符的表达式将被编译器视为无效。**



## **10.1.2 Grammars**

Once we have lexically analyzed a program into a stream of tokens, we now face the more challenging task of parsing the tokens stream into a formal structure. In other words, we have to figure out **how to group the tokens into language constructs like variable declarations, statements, expressions, and so on.** These grouping and classification tasks can be done by attempting to match the tokens stream on some predefined set of rules known as a grammar.

**一旦我们对一个Token流进行了词法分析，现在我们将面临将令牌流解析为正式结构的更具挑战性的任务。 换句话说，我们必须弄清楚如何将Token组合为语言结构，例如变量声明，语句，表达式等。 这些分组和分类任务可以通过尝试在称为语法的某些预定义规则集上匹配Token流来完成。**



Almost all programming languages, as well as most other formal languages used for describing the syntax of complex file types, can be specified using formalisms known as context-free grammars. **A context-free grammar is a set of rules specifying how syntactic elements in some language can be formed from simpler ones.** For example, the Java grammar allows us to combine the atoms 100,count, and <= into the expression count<=100. In a similar fashion, the Java grammar allows us to ascertain that the text count<=100 is a valid Java expression. Indeed, each grammar has a dual perspective. From a declarative standpoint, the grammar specifies allowable ways to combine tokens, also called terminals, into higher-level syntactic elements, also called non-terminals. From an analytic standpoint, the grammar is a prescription for doing the reverse: parsing a given input (set of tokens resulting from the tokenizing phase) into non-terminals, lower-level non-terminals, and eventually terminals that cannot be decomposed any further. Figure 10.3 gives an example of a typical grammar.

**几乎所有用于描述复杂文件类型语法的编程语言以及大多数其他形式语言都可以使用称为上下文无关文法的形式化进行指定。上下文无关的语法是一组规则，用于指定如何从较简单的语法元素形成某种语言的语法元素。例如，Java语法允许我们将原子100，count和<=组合成表达式count <= 100。以类似的方式，Java语法使我们可以确定文本数<= 100是有效的Java表达式。确实，每个语法都有双重视角。从声明的角度来看，语法指定了将标记（也称为终结符）组合为更高级别的语法元素（也称为非终结符）的允许方式。从分析的角度来看，语法是进行相反操作的处方：将给定的输入（由标记化阶段产生的标记集）解析为非终结点，较低级别的非终结点，以及最终无法进一步分解的终结点。**

这段有点迷。



In this chapter we specify grammars using the following notation: 

Terminal elements appear in bold text enclosed in single quotes, and non-terminal elements in regular font. When there is more than one way to parse a non-terminal, the “|” notation is used to list the alternative possibilities. Thus, figure 10.3 specifies that a statement can be either a whileStatement, or an ifStatement, and so on. Typically, grammar rules are highly recursive, and figure 10.3 is no exception. For example, statementSequence is either null, or a single statement followed by a semicolon and a statementSequence. This recursive definition can accommodate a sequence of 0, 1, 2, or any other positive number of semicolon-separated statements. As an exercise, the reader may use figure 10.3 to ascertain that the text appearing in the right side of the figure constitutes a valid C code. You may start by trying to match the entire text with statement, and work your way from there.

**在本章中，我们使用以下表示法指定语法：**

**终端元素以单引号括起来的粗体显示，非终端元素以常规字体显示。 当有多种方法解析非终结符时，将使用“ |”符号列出替代可能性。 因此，图10.3指定语句可以是whileStatement或ifStatement，依此类推。 通常，语法规则是高度递归的，图10.3也不例外。 例如，statementSequence为null，或者为单个语句，后跟分号和statementSequence。 此递归定义可以容纳0、1、2或任何其他正数的分号分隔的语句序列。 作为练习，读者可以使用图10.3确定出现在图右侧的文本构成有效的C代码。 您可能首先尝试将整个文本与语句匹配，然后从那里开始。**



![](https://tva1.sinaimg.cn/large/0082zybpgy1gbtg7ij4ahj30gg07gaaa.jpg)

这部分看不懂先看10.1.3就更直观些



## **10.1.3 Parsing**

The act of checking whether a grammar “accepts” an input text as valid is called parsing. As we noted earlier, parsing a given text means determining the exact correspondence between the text and the rules of a given grammar. Since the grammar rules are hierarchical, the output generated by the parser can be described in a tree-oriented data structure called a parse tree or a derivation tree. Figure 10.4 gives a typical example.

**检查语法是否“接受”输入文本为有效的行为称为解析。 正如我们前面提到的，解析给定的文本意味着确定文本和给定的语法规则之间的确切对应关系。 由于语法规则是分层的，因此可以在称为分析树或派生树的面向树的数据结构中描述解析器生成的输出。 图10.4给出了一个典型示例。**

![](https://tva1.sinaimg.cn/large/0082zybpgy1gbtga6b9f0j30gg0fhaal.jpg)

Note that as a side effect of the parsing process, the entire syntactic structure of the input text is uncovered. Some compilers represent this tree by an explicit data structure that is further used for code generation and error reporting. Other compilers (including the one that we will build) represent the program’s structure implicitly, generating code and reporting errors on the fly. Such compilers don’t have to hold the entire program structure in memory, but only the subtree associated with the presently parsed element. More about this later.

**注意，作为解析过程的副作用，将发现输入文本的整个语法结构。 一些编译器通过显式数据结构来表示该树，该数据结构还用于代码生成和错误报告。 其他编译器（包括我们将要编译的编译器）隐式表示程序的结构，生成代码并即时报告错误。 这样的编译器不必将整个程序结构保存在内存中，而只需将与当前已解析元素关联的子树保存在内存中即可。 稍后再详细介绍。**

**Recursive Descent Parsing** There are several algorithms for constructing parse trees. The top-down approach, also called recursive descent parsing, attempts to parse the tokens stream recursively, using the nested structure prescribed by the language grammar. Let us consider how a parser program that implements this strategy can be written.

 For every rule in the grammar describing a non-terminal, we can equip the parser program with a recursive routine designed to parse that non-terminal. If the non-terminal consists of terminal atoms only, the routine can simply process them. Otherwise, for every non-terminal building block in the rule’s right-hand side, the routine can recursively call the routine designed to parse this non-terminal. The process will continue recursively, until all the terminal atoms have been reached and processed.

**递归下降解析有几种构造解析树的算法。** 

**自上而下的方法（也称为递归下降解析）尝试使用语言语法规定的嵌套结构来递归地解析Token流。**

 **让我们考虑一下如何编写实现该策略的解析器程序。 对于语法中描述非终结符的每条规则，我们都可以为解析器程序配备一个递归例程，用于解析该非终结符。 如果非末端仅由末端原子组成，则例程可以简单地对其进行处理。 否则，对于规则右侧的每个非终端构建块，例程都可以递归调用设计为解析该非终端的例程。 该过程将递归进行，直到到达并处理了所有末端原子。**



To illustrate, suppose we have to write a recursive descent parser that follows the grammar from figure 10.3. Since the grammar has five derivation rules, the parser implementation can consist of five major routines: parseStatement(), parseWhileStatement (), parseIfStatement(), parseStatementSequence(), and parseExpression(). The parsing logic of these routines should follow the syntactic patterns appearing in the right-hand sides of the corresponding grammar rules. Thus parseStatement() should probably start its processing by determining what is the first token in the input. Having established the token’s identity, the routine could determine which statement we are in, and then call the parsing routine associated with this statement type.

**为了说明，假设我们必须编写一个遵循图10.3的语法的递归下降解析器。 由于语法具有五个派生规则，所以解析器实现可以包含五个主要例程：parseStatement（），parseWhileStatement（），parseIfStatement（），parseStatementSequence（）和parseExpression（）。 这些例程的解析逻辑应遵循相应语法规则右侧出现的语法模式。 因此parseStatement（）可能应该通过确定输入中的第一个标记是什么来开始其处理。 建立令牌的身份后，例程可以确定我们所在的语句，然后调用与此语句类型关联的解析例程。**

For example, if the input stream were that depicted in figure 10.4, the routine will establish that the first token is while, then call the parseWhileStatement() routine. According to the corresponding grammar rule, this routine should next attempt to read the terminals “while” and “(”, and then call parseExpression ( ) to parse the non-terminal expression. After parseExpression ( ) would return (having parsed the “count<=100” sequence in our example), the grammar dictates that parseWhileStatement() should attempt to read the terminal “)” and then recursively call parseStatement(). This call would continue recursively, until at some point only terminal atoms are read. Clearly, the same logic can also be used for detecting syntax errors in the source program. The better the compiler, the better will be its error diagnostics.

**例如，如果输入流是图10.4所示，则例程将确定第一个Token为while，然后调用parseWhileStatement（）例程。 根据相应的语法规则，该例程接下来应尝试读取终端“ while”和“（”，然后调用parseExpression（）来解析非终端表达式。parseExpression（）之后将返回（已解析“ count” 在我们的示例中<= 100”序列），语法规定parseWhileStatement（）应该尝试读取终端“）”，然后递归调用parseStatement（）。 该调用将以递归方式继续，直到在某些时候仅读取末端原子。 显然，相同的逻辑也可以用于检测源程序中的语法错误。 编译器越好，其错误诊断就越好。**

说白了就是根据树，将表达式从左到右调用parse函数（routine）解析。



**LL(0) Grammars** Recursive parsing algorithms are simple and elegant. The only possible complication arises when there are several alternatives for parsing non-terminals. For example, when parseStatement ( ) attempts to parse a statement, it does not know in advance whether this statement is a while-statement, an if-statement, or a bunch of statements enclosed in curly brackets. 

The span of possibilities is determined by the grammar, and in some cases it is easy to tell which alternative we are in. For example, consider figure 10.3. If the first token is “while,” it is clear that we are faced with a while statement, since this is the only alternative in the grammar that starts with a “while” token. This observation can be generalized as follows: whenever a non-terminal has several alternative derivation rules, the first token suffices to resolve without ambiguity which rule to use. Grammars that have this property are called *LL(0)*. These grammars can be handled simply and neatly by recursive descent algorithms.

**LL（0）语法递归解析算法既简单又优雅。当解析非终端有多种选择时，唯一可能的复杂性就会出现。例如，当parseStatement（）尝试解析一条语句时，它不预先知道该语句是while语句，if语句还是用大括号括起来的一堆语句。**

**可能性的范围由语法确定，在某些情况下，很容易分辨出我们所处的备选方案。例如，考虑图10.3。如果第一个标记是“ while”，则很显然我们要面对一个while语句，因为这是语法中唯一以“ while”标记开头的选择。可以将这种观察概括如下：每当非终结者具有多个替代派生规则时，第一个标记就足以毫无歧义地解析使用哪个规则。具有此属性的语法称为LL（0）。这些语法可以通过递归下降算法简单整洁地处理。**



When the first token does not suffice to resolve the element’s type, it is possible that a “look ahead” to the next token will settle the dilemma. Such parsing can obviously be done, but as we need to look ahead at more and more tokens down the stream, things start getting complicated. The Jack language grammar, which we now turn to present, is almost *LL(0)*, and thus it can be handled rather simply by a recursive descent parser. The only exception is the parsing of expressions, where just a little look ahead is necessary.

**当第一个标记不足以解决元素的类型时，下一个标记的“向前看”可能会解决这个难题。 显然可以进行这样的解析，但是由于我们需要向前看越来越多的令牌，因此事情开始变得复杂。 我们现在要介绍的杰克语言语法几乎是LL（0），因此可以通过递归下降解析器进行简单处理。 唯一的例外是表达式的解析，其中仅需略微向前看。**



# ***\*10.2 Specification\****

This section has two distinct parts. First, we specify the Jack language’s grammar. Next, we specify a syntax analyzer designed to parse programs according to this grammar.

**本节包含两个不同的部分。 首先，我们指定JACK语言的语法。 接下来，我们指定一个语法分析器，该语法分析器旨在根据该语法分析程序。**



## **10.2.1 The Jack Language Grammar**

The functional specification of the Jack language given in chapter 9 was aimed at Jack programmers. We now turn to giving a formal specification of the language, aimed at Jack compiler developers. Our grammar specification is based on the following conventions:

**‘xxx’:** quoted boldface is used for tokens that appear verbatim (“terminals”);

xxx: regular typeface is used for names of language constructs (“non-terminals”);

(): parentheses are used for grouping of language constructs;

x|y: indicates that either x or y can appear;

x?: indicates that x appears 0 or 1 times;

x*: indicates that x appears 0 or more times.

The Jack language syntax is given in figure 10.5, using the preceding conventions.

**第9章中给出的Jack语言的功能规范是针对Jack程序员的。 现在，我们转向针对Jack编译器开发人员的正式语言规范。 我们的语法规范基于以下约定：**

**“ xxx”：带引号的粗体字用于逐字显示的Token（“终端”）；**

**xxx：常规字体用于语言结构的名称（“非终端”）；**

**（）：括号用于对语言结构进行分组；**

**x | y：表示x或y都可以出现；**

**x ?：表示x出现0或1次；**

**x *：表示x出现0次或多次。**

**使用前面的约定，图10.5中给出了Jack语言的语法。**

![](https://tva1.sinaimg.cn/large/0082zybpgy1gbtgyow6g7j30gg0ggwfn.jpg)



![](https://tva1.sinaimg.cn/large/0082zybpgy1gbtgzksrrbj30gg0cc0tg.jpg)



## **10.2.2 A Syntax Analyzer for the Jack Language**

The main purpose of the syntax analyzer is to read a Jack program and “understand” its syntactic structure according to the Jack grammar. By understanding, we mean that the syntax analyzer must know, at each point in the parsing process, the structural identity of the program element that it is currently reading, namely, whether it is an expression, a statement, a variable name, and so on. The syntax analyzer must possess this syntactic knowledge in a complete recursive sense. Without it, it will be impossible to move on to code generation—the ultimate goal of the overall compiler.

**语法分析器的主要目的是读取Jack程序，并根据Jack语法“理解”其语法结构。 通过理解，我们的意思是语法分析器必须在解析过程的每个点都知道它当前正在读取的程序元素的结构标识，即它是否是表达式，语句，变量名等等。 上。 语法分析器必须在完全递归的意义上拥有这种语法知识。 没有它，就不可能继续进行代码生成，这是整个编译器的最终目标。**

The fact that the syntax analyzer “understands” the programmatic structure of the input can be demonstrated by having it print the processed text in some well-structured and easy-to-read format. One can think of several ways to cook up such a demonstration. In this book, we decided to have the syntax analyzer output an XML file whose marked-up format reflects the syntactic structure of the underlying program. By viewing this XML output file—a task that can be conveniently done with any Web browser—one should be able to tell right away if the syntax analyzer is doing the job or not.

**语法分析器“理解”输入的程序结构这一事实可以通过以某种结构良好且易于阅读的格式打印处理后的文本来证明。 可以想到几种方法来制作这样的演示。 在这本书中，我们决定让语法分析器输出一个XML文件，该文件的标记格式反映了底层程序的语法结构。 通过查看此XML输出文件（可以使用任何Web浏览器方便地完成的任务），一个人应该能够立即知道语法分析器是否正在执行此任务。**



## **10.2.3 The Syntax Analyzer’s Input**

The Jack syntax analyzer accepts a single command line parameter, as follows:

![](https://tva1.sinaimg.cn/large/0082zybpgy1gbth0im758j305j00a741.jpg)

Where *source* is either a file name of the form Xxx.jack (the extension is mandatory) or a directory name containing one or more . jack files (in which case there is no extension). The syntax analyzer compiles the Xxx.jack file into a file named Xxx.xml, created in the same directory in which the source file is located. If source is a directory name, each .jack file located in it is compiled, creating a corresponding .xml file in the same directory.

Each Xxx.jack file is a stream of characters. This stream should be tokenized into a stream of tokens according to the rules specified by the lexical elements of the Jack language (see figure 10.5, top). The tokens may be separated by an arbitrary number of space characters, newline characters, and comments, which are ignored. Comments are of the standard formats /* comment until closing */, /** API comment */, and // comment to end of line.

**其中source是格式为Xxx.jack的文件名（扩展名是必需的）或包含一个或多个的目录名。 插孔文件（在这种情况下，没有扩展名）。 语法分析器将Xxx.jack文件编译为名为Xxx.xml的文件，该文件在源文件所在的同一目录中创建。 如果source是目录名，则会编译其中的每个.jack文件，并在同一目录中创建一个相应的.xml文件。**

每个Xxx.jack文件都是字符流。 根据Jack语言的词汇元素指定的规则，应将此流标记为Token流（请参见图10.5，顶部）。 标记可以由任意数量的空格字符，换行符和注释分隔，这些字符将被忽略。 注释采用标准格式/ *注释，直到关闭* //  API注释 /和//注释到行尾。



## **10.2.4 The Syntax Analyzer’s Output**

Recall that the development of the Jack compiler is split into two stages (see figure 10.1), starting with the syntax analyzer. In this chapter, we want the syntax analyzer to emit an XML description of the input program, as illustrated in figure 10.6. In order to do so, the syntax analyzer has to recognize two major types of language constructs: terminal and non-terminal elements. These constructs are handled as follows.

**回想一下，Jack编译器的开发分为两个阶段（参见图10.1），从语法分析器开始。 在本章中，我们希望语法分析器发出输入程序的XML描述，如图10.6所示。 为此，语法分析器必须识别两种主要的语言构造类型：终端和非终端元素。 这些构造的处理如下。**



**Non-Terminals** Whenever a non-terminal language element of type xxx is encountered, the syntax analyzer should generate the marked-up output:

**非终端程序每当遇到类型为xxx的非终端语言元素时，语法分析器都应生成标记输出：**

![](https://tva1.sinaimg.cn/large/0082zybpgy1gbth2onm82j308w01cmwy.jpg)

Where xxx is one of the following (and only the following) non-terminals of the Jack grammar:

■ class, classVarDec, subroutineDec, parameterList, subroutineBody, varDec;

■ statements, whileSatement, ifStatement, returnStatement, letStatement, doStatement;

■ expression, term, expressionList.

**其中xxx是Jack语法的以下（且仅以下）非终结符之一：**
**■class，classVarDec，subroutineDec，parameterList，subroutineBody，varDec；**
**■语句，whileSatement，ifStatement，returnStatement，letStatement，doStatement；**
**■表达式，术语，expressionList。**



**Terminals** Whenever a terminal language element of type xxx is encountered, the syntax analyzer should generate the marked-up output:

**终端每当遇到类型为xxx的终端语言元素时，语法分析器都应生成标记输出：**

![](https://tva1.sinaimg.cn/large/0082zybpgy1gbth3hmrcxj303q00d741.jpg)

**其中xxx是Jack语言（在Jack语法的“词法元素”部分中指定）识别的五种Token类型之一，即关键字，符号，integerConstant，stringConstant或标识符。**
**图10.6显示了分析仪的输出，应该引起某种似曾相识的感觉。 在本章的前面，我们注意到可以将程序的结构分析成一个解析树。 的确，XML输出只是树的文本描述。 特别要注意的是，在解析树中，非终端节点形成一个“超级结构”，该超级结构描述了树的终端节点（令牌）如何被分组为语言结构。 此模式反映在XML输出中，其中非终端XML元素描述了终端XML项的排列方式。 以类似的方式，由令牌生成器生成的令牌形成XML输出的最低级别，就像它们形成程序的解析树的末尾叶子一样。**

![](https://tva1.sinaimg.cn/large/0082zybpgy1gbth4cv39lj30gg0ggq3m.jpg)



**Code Generation** We have just finished specifying the analyzer’s XML output. In the next chapter we replace the software that generates this output with software that generates executable VM code, leading to a full-scale Jack compiler.

**代码生成我们刚刚指定了分析器的XML输出。 在下一章中，我们将生成该输出的软件替换为生成可执行VM代码的软件，从而生成完整的Jack编译器。**



# ***\*10.3 Implementation\****

Section 10.2 gave all the information necessary to build a syntax analyzer for the Jack language, without any implementation details. This section describes a proposed software architecture for the syntax analyzer. We suggest arranging the implementation in three modules:• JackAnalyzer: top-level driver that sets up and invokes the other modules;• JackTokenizer: tokenizer;• CompilationEngine: recursive top-down parser.

These modules are designed to handle the language’s syntax. In the next chapter we extend this architecture with two additional modules that handle the language’s semantics: a symbol table and a *VM-code writer*. This will complete the construction of a full-scale compiler for the Jack language. Since the module that drives the parsing process in this project will also drive the overall compilation in the next project, we call it CompilationEngine.

**10.3实施**
**10.2节给出了为Jack语言构建语法分析器所需的所有信息，没有任何实现细节。 本节介绍了语法分析器的建议软件体系结构。 我们建议将实现分为三个模块：**
**•JackAnalyzer：设置并调用其他模块的顶级驱动程序；**
**•JackTokenizer：令牌生成器；**
**•CompilationEngine：递归自上而下的解析器。**
**这些模块旨在处理语言的语法。 在下一章中，我们用两个附加的模块来扩展该体系结构，这些模块处理语言的语义：符号表和VM代码编写器。 这将完成Jack语言的完整编译器的构建。 由于在该项目中驱动解析过程的模块也将在下一个项目中驱动整体编译，因此我们将其称为CompilationEngine。**



## **10.3.1 The \*JackAnalyzer\* Module**

The analyzer program operates on a given source, where source is either a file name of the form Xxx.jack or a directory name containing one or more such files. For each source Xxx.jack file, the analyzer goes through the following logic:

\1. Create a *JackTokenizer* from the Xxx.jack input file.

\2. Create an *output file* called Xxx.xml and prepare it for writing.

\3. Use the *CompilationEngine* to compile the input *JackTokenizer* into the *output file.*

**分析器程序在给定的源上运行，其中source是格式为Xxx.jack的文件名或包含一个或多个此类文件的目录名。 对于每个源Xxx.jack文件，分析器都会通过以下逻辑：**
**1.从Xxx.jack输入文件创建一个JackTokenizer。**
**2.创建一个名为Xxx.xml的输出文件，并准备编写。**
**3.使用CompilationEngine将输入JackTokenizer编译到输出文件中。**



## **10.3.2 The \*JackTokenizer\* Module**

**JackTokenizer:** Removes all comments and white space from the input stream and breaks it into Jack-language tokens, as specified by the Jack grammar.

**JackTokenizer：按照Jack语法的指定，从输入流中删除所有注释和空格，并将其分成Jack语言标记。**



![](https://tva1.sinaimg.cn/large/0082zybpgy1gbth7hq687j30gg0fkjsf.jpg)

## **10.3.3 The CompilationEngine Module**

**CompilationEngine:** Effects the actual compilation output. Gets its input from a JackTokenizer and emits its parsed structure into an output file/stream. The output is generated by a series of compilexxx ( ) routines, one for every syntactic element xxx of the Jack grammar. The contract between these routines is that each compilexxx ( ) routine should read the syntactic construct xxx from the input, advance ( ) the tokenizer exactly beyond xxx, and output the parsing of xxx. Thus, compilexxx ( ) may only be called if indeed xxx is the next syntactic element of the input.

In the first version of the compiler, described in chapter 10, this module emits a structured printout of the code, wrapped in XML tags. In the final version of the compiler, described in chapter 11, this module generates executable VM code. In both cases, the parsing logic and module API are exactly the same.

**CompilationEngine：影响实际的编译输出。 从JackTokenizer获取输入，并将其解析后的结构发送到输出文件/流中。 输出是由一系列的compilexxx（）例程生成的，对于Jack语法的每个语法元素xxx来说，一个例程。 这些例程之间的约定是，每个compilexxx（）例程都应从输入中读取语法构造xxx，将（token）标记器推进（）恰好超过xxx，并输出xxx的解析结果。 因此，仅当xxx是输入的下一个语法元素时，才可以调用compilexxx（）。**

**在第10章中介绍的编译器的第一个版本中，此模块发出包装在XML标记中的代码的结构化打印输出。 在第11章中介绍的编译器最终版本中，该模块生成可执行的VM代码。 在这两种情况下，解析逻辑和模块API都完全相同。**



![](https://tva1.sinaimg.cn/large/0082zybpgy1gbth8ao5nxj30dp07l3yu.jpg)



![](https://tva1.sinaimg.cn/large/0082zybpgy1gbth8hbhf7j30dp0gygmk.jpg)



# ***\*10.4 Perspective\****

Although it is convenient to describe the structure of computer programs using parse trees and XML files, it’s important to understand that compilers don’t necessarily have to maintain such data structures explicitly. For example, the parsing algorithm described in this chapter runs “on-line,” meaning that it parses the input as it reads it and does not keep the entire input program in memory. There are essentially two types of strategies for doing such parsing. The simpler strategy works top-down, and this is the one presented in this chapter. The more advanced algorithms, which work bottom-up, are not described here since they require some elaboration of theory.

Indeed, in this chapter we have sidestepped almost all the formal language theory studied in typical compilation courses. We were able to do so by choosing a very simple syntax for the Jack language—a syntax that can be easily compiled using recursive descent techniques. For example, the Jack grammar does not mandate the usual operator precedence in expressions evaluation (multiplication before addition, and so on). This has enabled us to avoid parsing algorithms that are more powerful yet much more technical than the elegant top-down parsing techniques presented in the chapter.

Another topic that was hardly mentioned in the chapter is how the syntax of languages is specified in general. There is a rich theory called formal languages that discusses properties of classes of languages, as well as metalanguages and formalisms for specifying them. This is also the point where computer science meets the study of human languages, leading to the vibrant area of research known as computational linguistics.

Finally, it is worth mentioning that syntax analyzers are not stand-alone programs, and are rarely written from scratch. Instead, programmers usually build tokenizers and parsers using a variety of “compiler generator” tools like LEX (for lexical analysis) and YACC (for Yet Another Compiler Compiler). These utilities receive as input a context-free grammar, and produce as output syntax analysis code capable of tokenizing and parsing programs written in that grammar. The generated code can then be customized to fit the specific compilation needs of the application at hand. Following the “show me” spirit of this book, we have chosen not to use such black boxes in the implementation of our compiler, but rather to build everything from the ground up.



**尽管使用解析树和XML文件来描述计算机程序的结构很方便，但重要的是要了解编译器不一定必须明确维护此类数据结构。例如，本章描述的解析算法是“在线”运行的，这意味着它在读取输入时会对其进行解析，并且不会将整个输入程序保留在内存中。进行此类解析的策略基本上有两种。自上而下的更简单的策略，这就是本章介绍的策略。自底向上工作的更高级算法在这里不再描述，因为它们需要对理论进行一些阐述。**

**确实，在本章中，我们回避了典型编译课程中研究的几乎所有形式语言理论。通过为Jack语言选择一种非常简单的语法，我们能够做到这一点，该语法可以使用递归下降技术轻松地进行编译。例如，杰克（Jack）语法没有在表达式求值（加法前相乘，依此类推）中规定通常的运算符优先级。这使我们能够避免使用比本章介绍的优雅的自上而下的解析技术更强大但技术更多的解析算法。**

**本章中几乎没有提到的另一个主题是语言的语法通常是如何指定的。有一种称为形式语言的丰富理论，它讨论语言类别的属性以及用于指定它们的元语言和形式主义。这也是计算机科学与人类语言研究的交汇点，从而导致了被称为计算语言学的充满活力的研究领域。**

**最后，值得一提的是语法分析器不是独立程序，很少从头开始编写。相反，程序员通常使用各种“编译器生成器”工具（例如LEX（用于词法分析）和YACC（用于Another Compiler编译器））来构建标记器和解析器。这些实用程序接收与上下文无关的语法作为输入，并生成能够标记和解析以该语法编写的程序的语法分析输出作为输出。然后可以对生成的代码进行定制，以适应手头应用程序的特定编译需求。遵循本书的“展示给我”的精神，我们选择在编译器的实现中不要使用这种黑盒子，而要从头开始构建所有内容**



# ***\*10.5 Project\****

The compiler construction spans two projects: 10 and 11. This section describes how to build the syntax analyzer described in this chapter. In the next chapter we extend this analyzer into a full-scale Jack compiler.

 

**Objective** Build a syntax analyzer that parses Jack programs according to the Jack grammar. The analyzer’s output should be written in XML, as defined in the specification section.

 

**Resources** The main tool in this project is the programming language in which you will implement the syntax analyzer. You will also need the supplied TextComparer utility, which allows comparing the output files generated by your analyzer to the compare files supplied by us. You may also want to inspect the generated and supplied output files using an XML viewer (any standard Web browser should do the job).

 

**Contract** Write the syntax analyzer program in two stages: tokenizing and parsing. Use it to parse all the . jack files mentioned here. For each source . jack file, your analyzer should generate an .xml output file. The generated files should be identical to the .xml compare-files supplied by us.

 

**Test Programs**

 

The syntax analyzer’s job is to parse programs written in the Jack language. Thus, a reasonable way to test your analyzer it is to have it parse several representative Jack programs. We supply two such test programs, called Square Dance and Array Test. The former includes all the features of the Jack language except for array processing, which appears in the latter. We also provide a simpler version of the Square Dance program, as explained in what follows.

For each one of the three programs, we supply all the Jack source files comprising the program. For each such Xxx.jack file, we supply two compare files named XxxT.xml and Xxx.xml. These files contain, respectively, the output that should be produced by a tokenizer and by a parser applied to Xxx . jack.

■ *Square Dance* (projects/10/Square): A trivial interactive “game” that enables moving a black square around the screen using the keyboard’s four arrow keys.

■ *Expressionless Square Dance* (projects/10/ExpressionlessSquare): An identical copy of Square Dance, except that each expression in the original program is replaced with a single identifier (some variable name in scope). For example, the Square class has a method that increases the size of the graphical square object by 2 pixels, as long as the new size does not cause the square image to spill over the screen’s boundaries. The code of this method is as follows.

![](https://tva1.sinaimg.cn/large/0082zybpgy1gbthamutx5j30dp055t8q.jpg)





Note that the replacement of expressions with variables has resulted in a nonsensical program that cannot be compiled by the supplied Jack compiler. Still, it follows all the Jack grammar rules. The expressionless class files have the same names as those of the original files, but they are located in a separate directory.

■ *Array test* (projects/10/ArrayTest): A single-class Jack program that computes the average of a user-supplied sequence of integers using array notation and array manipulation.



**Experimenting with the Test Programs** If you want, you can compile the Square Dance and Array Test programs using the supplied Jack compiler, then use the supplied VM emulator to run the compiled code. These activities are completely irrelevant to this project, but they serve to highlight the fact that the test programs are not just plain text (although this is perhaps the best way to think about them in the context of this project).

 

**Stage 1: Tokenizer**

 

First, implement the JackTokenizer module specified in section 10.3. When applied to a text file containing Jack code, the tokenizer should produce a list of tokens, each printed in a separate line along with its classification: symbol, keyword, identifier, integer constant, or string constant. The classification should be recorded using XML tags. Here is an example:

![](https://tva1.sinaimg.cn/large/0082zybpgy1gbthax6f6wj30dp0920so.jpg)



Note that in the case of string constants, the tokenizer throws away the double quote characters. That’s intentional.

The tokenizer’s output has two “peculiarities” dictated by XML conventions. First, an XML file must be enclosed in some begin and end tags, and that’s why the <tokens> and </tokens> tags were added to the output. Second, four of the symbols used in the Jack language (<, >, “, &) are also used for XML markup, and thus they cannot appear as data in XML files. To solve the problem, we require the tokenizer to output these tokens as &lt;, &gt;, &quot;, and &amp;, respectively. For example, in order for the text “<symbol> < </symbol>” to be displayed properly in a Web browser, the source XML should be written as “<symbol> &lt; </symbol>.”

 

**Testing Your Tokenizer**

■ Test your tokenizer on the Square Dance and Test Array programs. There is no need to test it on the expressionless version of the former.

■ For each source file Xxx.jack, have your tokenizer give the output file the name XxxT.xml. Apply your tokenizer to every class file in the test programs, then use the supplied TextComparer utility to compare the generated output to the supplied .xml compare files.

■ Since the output files generated by your tokenizer will have the same names and extensions as those of the supplied compare files, we suggest putting them in separate directories.

 

**Stage 2: Parser**

 

Next, implement the CompilationEngine module specified in section 10.3. Write each method of the engine, as specified in the API, and make sure that it emits the correct XML output. We recommend to start by writing a compilation engine that handles everything except expressions, and test it on the expressionless Square Dance program only. Next, extend the parser to handle expressions as well, and proceed to test it on the *Square Dance* and *Array Test* programs.

**Testing Your Parser**

■ Apply your CompilationEngine to the supplied test programs, then use the supplied TextComparer utility to compare the generated output to the supplied . xml compare files.

■ Since the output files generated by your analyzer will have the same names and extensions as those of the supplied compare files, we suggest putting them in separate directories.

■ Note that the indentation of the XML output is only for readability. Web browsers and the supplied TextComparer utility ignore white space.

